{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pdfminer.high_level import extract_text\n",
    "from pdfminer.layout import LAParams\n",
    "from pdfminer.pdfinterp import PDFResourceManager, PDFPageInterpreter\n",
    "from pdfminer.pdfpage import PDFPage\n",
    "from pdfminer.converter import PDFPageAggregator\n",
    "from pdfminer.layout import LTTextBox, LTTextLine, LTChar\n",
    "from IPython.display import display\n",
    "import fitz  # PyMuPDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique Font Information for random.pdf:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Font Style</th>\n",
       "      <th>Font Size</th>\n",
       "      <th>Color</th>\n",
       "      <th>Producer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sumit Ganesh Mesta</td>\n",
       "      <td>Helvetica</td>\n",
       "      <td>20</td>\n",
       "      <td>0.207840</td>\n",
       "      <td>iText® 5.5.12 ©2000-2017 iText Group NV (AGPL-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>A. P. Shah Institute of Technology</td>\n",
       "      <td>Helvetica</td>\n",
       "      <td>15</td>\n",
       "      <td>0.150327</td>\n",
       "      <td>iText® 5.5.12 ©2000-2017 iText Group NV (AGPL-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>Certificate ID :105173542b77279971c9fa0a05fad78a</td>\n",
       "      <td>Helvetica</td>\n",
       "      <td>10</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>iText® 5.5.12 ©2000-2017 iText Group NV (AGPL-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>Student ID :STU62d65aee5f4fe1658215150</td>\n",
       "      <td>Helvetica</td>\n",
       "      <td>10</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>iText® 5.5.12 ©2000-2017 iText Group NV (AGPL-...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Text Font Style  Font Size  \\\n",
       "0                                  Sumit Ganesh Mesta  Helvetica         20   \n",
       "18                 A. P. Shah Institute of Technology  Helvetica         15   \n",
       "52   Certificate ID :105173542b77279971c9fa0a05fad78a  Helvetica         10   \n",
       "100            Student ID :STU62d65aee5f4fe1658215150  Helvetica         10   \n",
       "\n",
       "        Color                                           Producer  \n",
       "0    0.207840  iText® 5.5.12 ©2000-2017 iText Group NV (AGPL-...  \n",
       "18   0.150327  iText® 5.5.12 ©2000-2017 iText Group NV (AGPL-...  \n",
       "52   0.000000  iText® 5.5.12 ©2000-2017 iText Group NV (AGPL-...  \n",
       "100  0.000000  iText® 5.5.12 ©2000-2017 iText Group NV (AGPL-...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique Font Information for Soham  Dalvi 623593.pdf:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Font Style</th>\n",
       "      <th>Font Size</th>\n",
       "      <th>Color</th>\n",
       "      <th>Producer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sumit Mesta</td>\n",
       "      <td>TYSYXI+OpenSans-Regular</td>\n",
       "      <td>16</td>\n",
       "      <td>0.2</td>\n",
       "      <td>iText 2.1.7 by 1T3XT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>77</td>\n",
       "      <td>TYSYXI+OpenSans-Regular</td>\n",
       "      <td>16</td>\n",
       "      <td>0.2</td>\n",
       "      <td>iText 2.1.7 by 1T3XT</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Text               Font Style  Font Size  Color  \\\n",
       "0   Sumit Mesta  TYSYXI+OpenSans-Regular         16    0.2   \n",
       "11           77  TYSYXI+OpenSans-Regular         16    0.2   \n",
       "\n",
       "                Producer  \n",
       "0   iText 2.1.7 by 1T3XT  \n",
       "11  iText 2.1.7 by 1T3XT  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pdfminer.high_level import extract_text\n",
    "from pdfminer.layout import LAParams\n",
    "from pdfminer.pdfinterp import PDFResourceManager, PDFPageInterpreter\n",
    "from pdfminer.pdfpage import PDFPage\n",
    "from pdfminer.converter import PDFPageAggregator\n",
    "from pdfminer.layout import LTTextBox, LTTextLine, LTChar\n",
    "from IPython.display import display\n",
    "import fitz  # PyMuPDF\n",
    "\n",
    "def extract_metadata(pdf_file):\n",
    "    try:\n",
    "        document = fitz.open(pdf_file)\n",
    "        metadata = document.metadata\n",
    "        return metadata\n",
    "    except Exception as e:\n",
    "        print(f\"Error extracting metadata from {pdf_file}: {e}\")\n",
    "        return {}\n",
    "\n",
    "def extract_font_information(pdf_file):\n",
    "    font_data = []\n",
    "    try:\n",
    "        with open(pdf_file, 'rb') as file:\n",
    "            rsrcmgr = PDFResourceManager()\n",
    "            laparams = LAParams()\n",
    "            device = PDFPageAggregator(rsrcmgr, laparams=laparams)\n",
    "            interpreter = PDFPageInterpreter(rsrcmgr, device)\n",
    "            for page_number, page in enumerate(PDFPage.get_pages(file), start=1):\n",
    "                interpreter.process_page(page)\n",
    "                layout = device.get_result()\n",
    "                for element in layout:\n",
    "                    if isinstance(element, (LTTextBox, LTTextLine)):\n",
    "                        for text_line in element:\n",
    "                            line_text = text_line.get_text().strip()\n",
    "                            for char in text_line:\n",
    "                                if isinstance(char, LTChar):\n",
    "                                    # Handle color extraction\n",
    "                                    color = getattr(char.graphicstate, 'ncolor', 'Unknown')\n",
    "                                    if isinstance(color, tuple):\n",
    "                                        color = sum(color) / len(color)  # Calculate the average of the tuple values\n",
    "                                    elif isinstance(color, np.ndarray):\n",
    "                                        color = np.mean(color) \n",
    "                                    elif isinstance(color, list):\n",
    "                                        color = sum(color) / len(color)\n",
    "\n",
    "                                    \n",
    "                                    font_data.append({\n",
    "                                        \"Text\": str(line_text),\n",
    "                                        \"Font Style\": str(char.fontname),\n",
    "                                        \"Font Size\": int(char.size),\n",
    "                                        \"Color\": float(color)\n",
    "                                    })\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {pdf_file}: {e}\")\n",
    "    return font_data\n",
    "\n",
    "def extract_font_information_with_metadata(pdf_file):\n",
    "    # Extract metadata\n",
    "    metadata = extract_metadata(pdf_file)\n",
    "    producer = str(metadata.get('producer', 'Unknown'))\n",
    "\n",
    "    # Extract font information\n",
    "    font_data = extract_font_information(pdf_file)\n",
    "    \n",
    "    # Add metadata 'producer' field to each record\n",
    "    for entry in font_data:\n",
    "        entry['Producer'] = producer\n",
    "    \n",
    "    return font_data\n",
    "\n",
    "# Extract font information with metadata from both PDFs\n",
    "pdf_file1 = \"./certificates_dataset/Cybersecurity_Certf.pdf\"\n",
    "font_info1 = extract_font_information_with_metadata(pdf_file1)\n",
    "font_info_df1 = pd.DataFrame(font_info1)\n",
    "\n",
    "pdf_file2 = \"./certificates_dataset/Redhat_Certf.pdf\"\n",
    "font_info2 = extract_font_information_with_metadata(pdf_file2)\n",
    "font_info_df2 = pd.DataFrame(font_info2)\n",
    "\n",
    "# Remove duplicate entries\n",
    "font_info_df1_unique = font_info_df1.drop_duplicates()\n",
    "font_info_df2_unique = font_info_df2.drop_duplicates()\n",
    "\n",
    "# Display the unique DataFrames\n",
    "print(\"Unique Font Information for random.pdf:\")\n",
    "display(font_info_df1_unique)\n",
    "\n",
    "print(\"Unique Font Information for Soham  Dalvi 623593.pdf:\")\n",
    "display(font_info_df2_unique)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File :  AIML_Cert (2) COMP.pdf\n",
      "File :  AWS_Cloud_Virtual_Internship.pdf\n",
      "File :  CelonisDefault20240423-31-gh2sdu.pdf\n",
      "File :  CF_AWS_Academy_Graduate___AWS_Academy_Cloud_Foundations_Badge20230125-30-k2x1xb.pdf\n",
      "File :  Cybersecurity_Certf.pdf\n",
      "File :  Data_Analysis_Using_Python_Badge20240321-37-7tk5a0.pdf\n",
      "File :  Fundamentals of Cloud Security _ Beacon.pdf\n",
      "File :  Fundamentals of Network Security _ Beacon.pdf\n",
      "File :  IBM DA0101EN Certificate _ Cognitive Class.pdf\n",
      "File :  IIT SPOKEN_Python.pdf\n",
      "Error processing ./certificates_dataset\\IIT SPOKEN_Python.pdf: float() argument must be a string or a real number, not 'NoneType'\n",
      "File :  IITSPOKEN_Linux.pdf\n",
      "Error processing ./certificates_dataset\\IITSPOKEN_Linux.pdf: float() argument must be a string or a real number, not 'NoneType'\n",
      "File :  INC1.pdf\n",
      "File :  INC2.pdf\n",
      "File :  Introduction to Cybersecurity _ Beacon.pdf\n",
      "File :  JNCAA-Certiciate of Attendance_comp.pdf\n",
      "File :  JNCIA-Certiciate of Attendance_comp.pdf\n",
      "File :  Juniper Networks Cloud Virtual comp.pdf\n",
      "File :  Juniper Networks Cloud Virtual.pdf\n",
      "File :  ML_AWS_Academy_Graduate___AWS_Academy_Machine_Learning_Foundations_Badge20230126-32-bdaztc.pdf\n",
      "File :  NK2.pdf\n",
      "File :  NKG1.pdf\n",
      "File :  NPTEL DAA Certificate.pdf\n",
      "File :  random.pdf\n",
      "File :  Redhat_Certf.pdf\n",
      "File :  Redhat_Report.pdf\n",
      "Error processing ./certificates_dataset\\Redhat_Report.pdf: float() argument must be a string or a real number, not 'NoneType'\n",
      "File :  SANKALP-GUNJAL-Participant-Certificate (2).pdf\n",
      "Error processing ./certificates_dataset\\SANKALP-GUNJAL-Participant-Certificate (2).pdf: float() argument must be a string or a real number, not 'NoneType'\n",
      "File :  Soham  Dalvi 312012.pdf\n",
      "File :  Soham  Dalvi 623593.pdf\n",
      "File :  Soham  Dalvi 6844.pdf\n",
      "File :  Soham  Mahendra Dalvi 755302.pdf\n",
      "File :  Soham Mahendra Dalvi 764282.pdf\n",
      "File :  SOHAM-DALVI-Participant-Certificate (1).pdf\n",
      "Error processing ./certificates_dataset\\SOHAM-DALVI-Participant-Certificate (1).pdf: float() argument must be a string or a real number, not 'NoneType'\n",
      "File :  SOHAM-DALVI-Participant-Certificate (2).pdf\n",
      "Error processing ./certificates_dataset\\SOHAM-DALVI-Participant-Certificate (2).pdf: float() argument must be a string or a real number, not 'NoneType'\n",
      "File :  SOHAM-DALVI-Participant-Certificate (3).pdf\n",
      "Error processing ./certificates_dataset\\SOHAM-DALVI-Participant-Certificate (3).pdf: float() argument must be a string or a real number, not 'NoneType'\n",
      "File :  SOHAM-DALVI-Participant-Certificate (4).pdf\n",
      "Error processing ./certificates_dataset\\SOHAM-DALVI-Participant-Certificate (4).pdf: float() argument must be a string or a real number, not 'NoneType'\n",
      "File :  SOHAM-DALVI-Participant-Certificate.pdf\n",
      "Error processing ./certificates_dataset\\SOHAM-DALVI-Participant-Certificate.pdf: float() argument must be a string or a real number, not 'NoneType'\n",
      "File :  SumitMesta-Linux Essentials-certificate.pdf\n",
      "File :  SumitMesta-Programming Esse-certificate (4).pdf\n",
      "File :  The Fundamentals of SOC (Security Operations Center) _ Beacon.pdf\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pdfminer.high_level import extract_text\n",
    "from pdfminer.layout import LAParams\n",
    "from pdfminer.pdfinterp import PDFResourceManager, PDFPageInterpreter\n",
    "from pdfminer.pdfpage import PDFPage\n",
    "from pdfminer.converter import PDFPageAggregator\n",
    "from pdfminer.layout import LTTextBox, LTTextLine, LTChar\n",
    "from IPython.display import display\n",
    "import fitz, os\n",
    "\n",
    "def extract_metadata(pdf_file):\n",
    "    try:\n",
    "        document = fitz.open(pdf_file)\n",
    "        metadata = document.metadata\n",
    "        return metadata\n",
    "    except Exception as e:\n",
    "        print(f\"Error extracting metadata from {pdf_file}: {e}\")\n",
    "        return {}\n",
    "\n",
    "def extract_font_information(pdf_file):\n",
    "    font_data = []\n",
    "    structure = {\n",
    "        \"number_of_pages\": 0,\n",
    "        \"fonts\": set(),\n",
    "        \"font_colors\": [],\n",
    "    }\n",
    "    try:\n",
    "        with open(pdf_file, 'rb') as file:\n",
    "            rsrcmgr = PDFResourceManager()\n",
    "            laparams = LAParams()\n",
    "            device = PDFPageAggregator(rsrcmgr, laparams=laparams)\n",
    "            interpreter = PDFPageInterpreter(rsrcmgr, device)\n",
    "            for page_number, page in enumerate(PDFPage.get_pages(file), start=1):\n",
    "                interpreter.process_page(page)\n",
    "                layout = device.get_result()\n",
    "                for element in layout:\n",
    "                    if isinstance(element, (LTTextBox, LTTextLine)):\n",
    "                        for text_line in element:\n",
    "                            line_text = text_line.get_text().strip()\n",
    "                            for char in text_line:\n",
    "                                if isinstance(char, LTChar):\n",
    "                                    # Handle color extraction\n",
    "                                    color = getattr(char.graphicstate, 'ncolor', 'Unknown')\n",
    "                                    if isinstance(color, tuple):\n",
    "                                        color = sum(color) / len(color)  # Calculate the average of the tuple values\n",
    "                                    elif isinstance(color, np.ndarray):\n",
    "                                        color = np.mean(color) \n",
    "                                    elif isinstance(color, list):\n",
    "                                        color = sum(color) / len(color)\n",
    "                                    \n",
    "                                    font_data.append({\n",
    "                                        \"Text\": str(line_text),\n",
    "                                        \"Font Style\": str(char.fontname),\n",
    "                                        \"Font Size\": float(char.size),\n",
    "                                        \"Color\": float(color),\n",
    "                                        \"Label\" : int(1)\n",
    "                                    })\n",
    "\n",
    "                                    # Add font information to structure\n",
    "                                    font_info = (char.fontname, char.size, color)\n",
    "                                    structure[\"fonts\"].add(char.fontname)\n",
    "                                    structure[\"font_colors\"].append(font_info)\n",
    "                                    \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {pdf_file}: {e}\")\n",
    "    return font_data\n",
    "\n",
    "def extract_image_count(pdf_file):\n",
    "    try:\n",
    "        document = fitz.open(pdf_file)\n",
    "        image_count = 0\n",
    "        for page_num in range(len(document)):\n",
    "            page = document[page_num]\n",
    "            image_count += len(page.get_images(full=True))\n",
    "        return image_count\n",
    "    except Exception as e:\n",
    "        print(f\"Error counting images in {pdf_file}: {e}\")\n",
    "        return 0\n",
    "\n",
    "def extract_font_information_with_metadata_and_images(pdf_file):\n",
    "    # Extract metadata\n",
    "    metadata = extract_metadata(pdf_file)\n",
    "    producer = str(metadata.get('producer', 'Unknown'))\n",
    "\n",
    "    # Extract font information\n",
    "    font_data = extract_font_information(pdf_file)\n",
    "    \n",
    "    # Extract image count\n",
    "    image_count = extract_image_count(pdf_file)\n",
    "    \n",
    "    # Add metadata 'producer' field and image count to each record\n",
    "    for entry in font_data:\n",
    "        entry['Producer'] = producer\n",
    "        entry['Image Count'] = image_count\n",
    "    \n",
    "    return font_data\n",
    "\n",
    "# Directory containing the PDF files\n",
    "directory_path = \"./certificates_dataset\"\n",
    "\n",
    "# Iterate through all PDF files in the directory\n",
    "for filename in os.listdir(directory_path):\n",
    "    if filename.endswith(\".pdf\"):\n",
    "        print(\"File : \", filename)\n",
    "        pdf_file = os.path.join(directory_path, filename)\n",
    "        pdf_ore = extract_font_information_with_metadata_and_images(pdf_file)\n",
    "        pdf_mineral = pd.DataFrame(pdf_ore)\n",
    "        pdf_mineral = pdf_mineral.drop_duplicates()\n",
    "        pdf_mineral.to_csv(\"real_cert.csv\", mode='a', header=not os.path.exists(\"real_cert.csv\"), index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[144]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       1.00      1.00      1.00       144\n",
      "\n",
      "    accuracy                           1.00       144\n",
      "   macro avg       1.00      1.00      1.00       144\n",
      "weighted avg       1.00      1.00      1.00       144\n",
      "\n",
      "The PDF is genuine.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\abc\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_csv(\"real_cert.csv\")\n",
    "\n",
    "# Define features and target\n",
    "X = data.drop(columns=['Label'])\n",
    "y = data['Label']\n",
    "\n",
    "# Categorical and numerical features\n",
    "categorical_features = ['Font Style', 'Producer']\n",
    "numerical_features = ['Font Size', 'Color', 'Image Count']\n",
    "\n",
    "# Preprocessing pipelines\n",
    "categorical_transformer = OneHotEncoder(handle_unknown='ignore')\n",
    "numerical_transformer = StandardScaler()\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numerical_transformer, numerical_features),\n",
    "        ('cat', categorical_transformer, categorical_features)\n",
    "    ])\n",
    "\n",
    "# Define the model pipeline\n",
    "model = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', RandomForestClassifier(random_state=42))\n",
    "])\n",
    "\n",
    "# Split data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Example: Predict on a new PDF's features\n",
    "new_pdf_features = {\n",
    "    'Text': \"...\", \n",
    "    'Font Style': \"Random font\", \n",
    "    'Font Size': 12, \n",
    "    'Color': 0.5, \n",
    "    'Producer': \"Producer Name\", \n",
    "    'Image Count': 2\n",
    "}\n",
    "new_pdf_df = pd.DataFrame([new_pdf_features])\n",
    "predicted_label = model.predict(new_pdf_df)\n",
    "\n",
    "if predicted_label == 0:\n",
    "    print(f\"The PDF is likely fake. Producer: {new_pdf_features['Producer']}\")\n",
    "else:\n",
    "    print(\"The PDF is genuine.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
